---
name: "Ollama"
version: "0.1.28.2"
slug: "ollama"
description: |
  Ollama 
  
  Runs offine LLM models on your local machine without sending data to the cloud.
arch:
  - aarch64
  - amd64
map: 
  - share:rw
boot: auto
codenotary: "red.avtovo@gmail.com"
image: "ghcr.io/j0rsa/haddon-ollama-{arch}"
udev: false
url: https://github.com/j0rsa/home-assistant-addons
ports:
  11434/tcp: 11434
ports_description:
  11434/tcp: API port
