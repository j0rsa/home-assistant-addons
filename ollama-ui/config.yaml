---
name: "Open WebUI"
version: "0.1.1"
slug: "open_webui"
description: |
  Open WebUI (Formerly Ollama WebUI)
  
  Open WebUI is an [extensible](https://github.com/open-webui/pipelines), feature-rich, and user-friendly 
  self-hosted WebUI designed to operate entirely offline. 
  It supports various LLM runners, including Ollama and OpenAI-compatible APIs. 
  For more information, be sure to check out our [Open WebUI Documentation](https://docs.openwebui.com/).
  
  [repo](https://github.com/open-webui/open-webui/tree/main)
arch:
  - aarch64
  - amd64
boot: auto
map: 
  - share:rw
options:
  ollama_api_url: "http://ollama:11434"
schema:
  ollama_api_url: url?
codenotary: "red.avtovo@gmail.com"
image: "ghcr.io/j0rsa/ollama-ui-{arch}"
ports:
  8080/tcp: 5000
ports_description:
  8080/tcp: Web UI port
udev: false
url: https://github.com/j0rsa/home-assistant-addons
